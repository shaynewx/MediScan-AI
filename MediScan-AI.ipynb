{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buLE0OZxzhBN"
   },
   "source": [
    "## Model training and result generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPMCvDrIjD-V",
    "outputId": "7f5f41d6-21b2-4e3a-a4ed-304b84d1a110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Accuracy: 0.7066666666666667, F1 Score: 0.06382978723404255, Precision: 0.375, Recall: 0.03488372093023256, ROC AUC: 0.5207020212997174, Confusion Matrix: [[209   5]\n",
      " [ 83   3]], Custom Loss: 0.6098601447036104\n",
      "Label 1 - Accuracy: 0.8928571428571429, F1 Score: 0.8186046511627908, Precision: 0.967032967032967, Recall: 0.7096774193548387, ROC AUC: 0.8554771505376345, Confusion Matrix: [[237   3]\n",
      " [ 36  88]], Custom Loss: 0.44835687109284156\n",
      "Label 2 - Accuracy: 0.9318801089918256, F1 Score: 0.8803827751196173, Precision: 0.989247311827957, Recall: 0.7931034482758621, ROC AUC: 0.9183953839813161, Confusion Matrix: [[250   1]\n",
      " [ 24  92]], Custom Loss: 0.40911395440259163\n",
      "Label 3 - Accuracy: 0.8729729729729729, F1 Score: 0.7929515418502202, Precision: 0.9090909090909091, Recall: 0.703125, ROC AUC: 0.8427976497933884, Confusion Matrix: [[233   9]\n",
      " [ 38  90]], Custom Loss: 0.4546024046997047\n",
      "Label 4 - Accuracy: 0.9110512129380054, F1 Score: 0.8630705394190872, Precision: 0.9541284403669725, Recall: 0.7878787878787878, ROC AUC: 0.8852225180677064, Confusion Matrix: [[234   5]\n",
      " [ 28 104]], Custom Loss: 0.43589536194407513\n",
      "Label 5 - Accuracy: 0.75, F1 Score: 0.05063291139240506, Precision: 0.4, Recall: 0.02702702702702703, ROC AUC: 0.5440684046878738, Confusion Matrix: [[223   3]\n",
      " [ 72   2]], Custom Loss: 0.5709635163040101\n",
      "Label 6 - Accuracy: 0.8852459016393442, F1 Score: 0.8220338983050848, Precision: 0.9797979797979798, Recall: 0.708029197080292, ROC AUC: 0.8479265610556849, Confusion Matrix: [[227   2]\n",
      " [ 40  97]], Custom Loss: 0.444025226900557\n",
      "Label 7 - Accuracy: 0.8663101604278075, F1 Score: 0.818840579710145, Precision: 0.904, Recall: 0.7483443708609272, ROC AUC: 0.8572743741276394, Confusion Matrix: [[211  12]\n",
      " [ 38 113]], Custom Loss: 0.4553535114642568\n",
      "Label 8 - Accuracy: 0.6233333333333333, F1 Score: 0.22068965517241382, Precision: 0.48484848484848486, Recall: 0.14285714285714285, ROC AUC: 0.5658482142857142, Confusion Matrix: [[171  17]\n",
      " [ 96  16]], Custom Loss: 0.6551256868469486\n",
      "Label 9 - Accuracy: 0.73, F1 Score: 0.047058823529411764, Precision: 0.6666666666666666, Recall: 0.024390243902439025, ROC AUC: 0.4937905571716268, Confusion Matrix: [[217   1]\n",
      " [ 80   2]], Custom Loss: 0.6097914999524202\n",
      "Label 10 - Accuracy: 0.7533333333333333, F1 Score: 0.026315789473684213, Precision: 0.5, Recall: 0.013513513513513514, ROC AUC: 0.5768356852427649, Confusion Matrix: [[225   1]\n",
      " [ 73   1]], Custom Loss: 0.5616214591472244\n",
      "Average Accuracy: 0.8112409848327666\n",
      "Average F1 Score: 0.4913100865789912\n",
      "Average Precision: 0.7390738872392671\n",
      "Average Recall: 0.4266208974255511\n",
      "Average ROC AUC: 0.7189398654773697\n",
      "Overall Confusion Matrix: \n",
      "[[2437   59]\n",
      " [ 608  608]]\n",
      "Average Custom Loss: 0.5140645124962036\n",
      "\n",
      "The size of final prediction (700, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import (accuracy_score,f1_score,precision_score,recall_score,roc_auc_score,confusion_matrix)\n",
    "import joblib\n",
    "\n",
    "\n",
    "X_train = np.load('/content/X_train.npy')\n",
    "y_train = np.load('/content/y_train.npy')\n",
    "\n",
    "# handle missing value in X_train: If there are more than 200 NaN values, delete the column directly\n",
    "nan_counts = np.sum(np.isnan(X_train), axis=0)\n",
    "columns_to_drop = [i for i, count in enumerate(nan_counts) if count > 200]\n",
    "X_train_cleaned = np.delete(X_train, columns_to_drop, axis=1)\n",
    "\n",
    "# Fill in remaining NaN values: use mean if continuous values, mode if discrete values\n",
    "unique_values_per_column = [np.unique(X_train_cleaned[:, i]).size for i in range(X_train_cleaned.shape[1])]\n",
    "# print( unique_values_per_column)\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.02  # Define the threshold as 2% of the sample size\n",
    "samples_count = X_train_cleaned.shape[0]\n",
    "\n",
    "# Initialize discrete and continuous feature index lists\n",
    "discrete_indices = []\n",
    "continuous_indices = []\n",
    "\n",
    "for i, unique_count in enumerate(unique_values_per_column):\n",
    "    # Case 1: If it is a continuous value, fill the NaN values with the mean of the column (exclude all NaN values)\n",
    "    if unique_count / samples_count >= threshold:\n",
    "        continuous_indices.append(i)\n",
    "        column_mean = np.nanmean(X_train_cleaned[:, i])\n",
    "        nan_indices = np.where(np.isnan(X_train_cleaned[:, i]))\n",
    "        X_train_cleaned[nan_indices, i] = column_mean\n",
    "\n",
    "    # Case 2: If it is a discrete value, fill the NaN values using mode padding (exclude all NaN values)\n",
    "    else:\n",
    "        discrete_indices.append(i)\n",
    "        non_nan_values = X_train_cleaned[:, i][~np.isnan(X_train_cleaned[:, i])]\n",
    "        if non_nan_values.size > 0:\n",
    "          mode_result = stats.mode(non_nan_values)\n",
    "          mode_value = mode_result.mode if mode_result.mode.size == 1 else mode_result.mode[0]\n",
    "          nan_indices = np.where(np.isnan(X_train_cleaned[:, i]))\n",
    "          X_train_cleaned[nan_indices, i] = mode_value\n",
    "\n",
    "# Check if there are still NaN values\n",
    "nan_counts_after_filling = np.sum(np.isnan(X_train_cleaned), axis=0)\n",
    "\n",
    "# Normalization\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_indices),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), discrete_indices)\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to convert X_train_cleaned\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train_cleaned)\n",
    "\n",
    "# Save the fitted preprocessor for later use\n",
    "joblib.dump(preprocessor, '/content/preprocessor.joblib')\n",
    "\n",
    "\n",
    "# Make different feature selections for each label and delete columns with an importance of 0\n",
    "important_features_indices = {}\n",
    "\n",
    "for i in range(y_train.shape[1]):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_preprocessed, y_train[:, i])\n",
    "    feature_importances = model.feature_importances_\n",
    "    important_indices = np.where(feature_importances > 0)[0]\n",
    "    important_features = X_train_preprocessed[:, important_indices]\n",
    "\n",
    "    # Save a dataset of important features for each label\n",
    "    np.save(f'/content/importance_data/X_train_important_label_{i}.npy', important_features)\n",
    "    # Save an index of important features for each label\n",
    "    important_features_indices[i] = important_indices\n",
    "    # print(f\"Label {i} - Retained features: {len(important_indices)} out of {X_train_preprocessed.shape[1]}\")\n",
    "\n",
    "np.save('/content/important_features_indices.npy', important_features_indices)  # Save all indices as one file\n",
    "\n",
    "#y_train is a two-dimensional array, each column represents a label\n",
    "y_train = np.load('/content/y_train.npy')\n",
    "\n",
    "\n",
    "#Iterate through each label\n",
    "for i in range(y_train.shape[1]):\n",
    "    # Load important feature data for each tag\n",
    "    X_train_important_path = f'/content/importance_data/X_train_important_label_{i}.npy'\n",
    "    X_train_important = np.load(X_train_important_path)\n",
    "\n",
    "    # Check if oversampling is required\n",
    "    class_counts = np.bincount(y_train[:, i])\n",
    "    imbalance_ratio = class_counts[1] / class_counts[0] if class_counts[0] != 0 else np.inf\n",
    "\n",
    "    # Save processed data\n",
    "    resampled_X_path = f'/content/resample_data/X_train_resampled_label_{i}.npy'\n",
    "    resampled_y_path = f'/content/resample_data/y_train_resampled_label_{i}.npy'\n",
    "\n",
    "    if imbalance_ratio < 0.35:\n",
    "        # Only copy positive samples\n",
    "        positive_indices = np.where(y_train[:, i] == 1)[0]\n",
    "        X_to_duplicate = X_train_important[positive_indices]\n",
    "        y_to_duplicate = y_train[positive_indices, i]\n",
    "\n",
    "        # Copy the positive sample and corresponding label\n",
    "        X_duplicated = np.concatenate([X_train_important, X_to_duplicate])\n",
    "        y_duplicated = np.concatenate([y_train[:, i], y_to_duplicate])\n",
    "\n",
    "        # Save the oversampled data\n",
    "        np.save(resampled_X_path, X_duplicated)\n",
    "        np.save(resampled_y_path, y_duplicated)\n",
    "    else:\n",
    "        # If oversampling is not required, copy only the column of the current label\n",
    "        shutil.copyfile(X_train_important_path, resampled_X_path)\n",
    "        np.save(resampled_y_path, y_train[:, i])\n",
    "\n",
    "\n",
    "# Load the oversampled size of each tag\n",
    "for i in range(y_train.shape[1]):\n",
    "    X_train_resampled = np.load(f'/content/resample_data/X_train_resampled_label_{i}.npy')\n",
    "    y_train_resampled = np.load(f'/content/resample_data/X_train_resampled_label_{i}.npy')\n",
    "    # print(f\"X_train_resampled_{i}\", X_train_resampled.shape)\n",
    "    # print(f\"y_train_resampled_{i}\", y_train_resampled.shape)\n",
    "\n",
    "\n",
    "# Initialize evaluation list\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "confusion_matrices = []\n",
    "loss_values = []\n",
    "\n",
    "# Define loss function\n",
    "def custom_loss(y_true, y_pred_proba):\n",
    "    epsilon = 1e-15\n",
    "    y_pred_proba = np.clip(y_pred_proba, epsilon, 1 - epsilon)\n",
    "    loss_per_sample = -np.mean(y_true * np.log(y_pred_proba) + (1 - y_true) * np.log(1 - y_pred_proba))\n",
    "    return loss_per_sample\n",
    "\n",
    "\n",
    "\n",
    "# predict each label\n",
    "for i in range(y_train.shape[1]):\n",
    "    X = np.load(f'/content/resample_data/X_train_resampled_label_{i}.npy')\n",
    "    y = np.load(f'/content/resample_data/y_train_resampled_label_{i}.npy')\n",
    "\n",
    "    # Partition the data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train a random forest model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get the feature index whose importance is not 0\n",
    "    feature_importances = model.feature_importances_\n",
    "    # feature_importances_dict[i] = feature_importances\n",
    "\n",
    "    # Save model\n",
    "    dump(model, f'/content/models/model_label_{i}.joblib')\n",
    "\n",
    "    # Make prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate each evaluation metric\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Append into list\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    confusion_matrices.append(confusion)\n",
    "\n",
    "    # Caculate loss value\n",
    "    loss = custom_loss(y_test, y_pred_proba)\n",
    "    loss_values.append(loss)\n",
    "\n",
    "    print(f\"Label {i} - Accuracy: {acc}, F1 Score: {f1}, Precision: {precision}, Recall: {recall}, ROC AUC: {roc_auc}, Confusion Matrix: {confusion}, Custom Loss: {loss}\")\n",
    "\n",
    "# Calculate average evaluation metric\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_roc_auc = np.mean(roc_auc_scores)\n",
    "# For confusion matrices, they are accumulated to get the overall confusion matrix\n",
    "overall_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "\n",
    "# Calculate the average custom loss value\n",
    "average_loss = np.mean(loss_values)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Average F1 Score: {average_f1_score}\")\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average ROC AUC: {average_roc_auc}\")\n",
    "print(f\"Overall Confusion Matrix: \\n{overall_confusion_matrix}\")\n",
    "print(f\"Average Custom Loss: {average_loss}\")\n",
    "\n",
    "\n",
    "# First do preprocessing on X_test\n",
    "X_test = np.load('/content/X_test.npy')\n",
    "\n",
    "# Remove the same columns removed from X_train\n",
    "X_test_cleaned = np.delete(X_test, columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "# Fill missing values for continuous features\n",
    "for i in continuous_indices:\n",
    "    column_mean = np.nanmean(X_test_cleaned[:, i])\n",
    "    nan_indices = np.where(np.isnan(X_test_cleaned[:, i]))\n",
    "    X_test_cleaned[nan_indices, i] = column_mean\n",
    "\n",
    "# Fill missing values for discrete features\n",
    "for i in discrete_indices:\n",
    "    non_nan_values = X_test_cleaned[:, i][~np.isnan(X_test_cleaned[:, i])]\n",
    "    if non_nan_values.size > 0:\n",
    "        mode_result = stats.mode(non_nan_values)\n",
    "        mode_value = mode_result.mode if mode_result.mode.size == 1 else mode_result.mode[0]\n",
    "        nan_indices = np.where(np.isnan(X_test_cleaned[:, i]))\n",
    "        X_test_cleaned[nan_indices, i] = mode_value\n",
    "\n",
    "# Apply the same preprocessing (scaling and encoding)\n",
    "# Load the fitted preprocessor\n",
    "preprocessor = joblib.load('/content/preprocessor.joblib')\n",
    "\n",
    "# Apply the preprocessing to the test set\n",
    "X_test_preprocessed = preprocessor.transform(X_test_cleaned)\n",
    "# print(X_test_preprocessed.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Load the number of saved features\n",
    "important_features_indices = np.load('/content/important_features_indices.npy', allow_pickle=True).item()\n",
    "\n",
    "\n",
    "# Prepare to store predictions for each label\n",
    "predictions = np.zeros((X_test_preprocessed.shape[0], len(important_features_indices)))\n",
    "\n",
    "# Load models and predict for each label\n",
    "for label, indices in important_features_indices.items():\n",
    "    model = joblib.load(f'/content/models/model_label_{label}.joblib')\n",
    "    # Select the important features for the label\n",
    "    X_test_important = X_test_preprocessed[:, indices]\n",
    "    # Predict using the corresponding model\n",
    "    predictions[:, label] = model.predict(X_test_important)\n",
    "\n",
    "# Save the predictions array to a file\n",
    "np.save('y_test.npy', predictions)\n",
    "\n",
    "prediction = np.load('/content/y_test.npy')\n",
    "print()\n",
    "print(\"The size of final prediction\", prediction.shape)\n",
    "# for i in range(prediction.shape[0]):\n",
    "#   print(f\"The prediction of {i}th sample \", prediction[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM-O4YSk1fST",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Code for deleting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Vs2zVW01sBm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# delete all X_train_important_label_*.npy\n",
    "for filename in glob.glob('/content/importance_data/X_train_important_label_*.npy'):\n",
    "    os.remove(filename)\n",
    "\n",
    "\n",
    "# delete all X_train_important_label_*.npy\n",
    "for filename in glob.glob('/content/resample_data/X_train_resampled_label_*.npy'):\n",
    "    os.remove(filename)\n",
    "\n",
    "# delete all  y_train_resampled_label_*.npy\n",
    "for filename in glob.glob('/content/resample_data/y_train_resampled_label_*.npy'):\n",
    "    os.remove(filename)\n",
    "\n",
    "\n",
    "for filename in glob.glob('/content/models/model_label_*.joblib'):\n",
    "    os.remove(filename)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
